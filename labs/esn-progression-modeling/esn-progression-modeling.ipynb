{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ESN Progression Modeling Lab\n",
        "\n",
        "## Echo State Networks for Temporal Disease Progression Prediction\n",
        "\n",
        "This lab implements Echo State Networks (ESN) for predicting the temporal progression of skin conditions. ESNs are a type of recurrent neural network particularly suited for time series prediction due to their reservoir computing approach.\n",
        "\n",
        "### Key Capabilities\n",
        "\n",
        "- **Disease Progression Prediction**: Forecast condition severity over time\n",
        "- **Treatment Response Modeling**: Predict how patients respond to treatments\n",
        "- **Pattern Recognition**: Identify flare cycles and seasonal patterns\n",
        "- **Healing Time Estimation**: Estimate recovery trajectories\n",
        "\n",
        "### Why Echo State Networks?\n",
        "\n",
        "ESNs are ideal for medical time series because:\n",
        "1. **Fast Training**: Only output weights need training\n",
        "2. **Temporal Memory**: Reservoir captures temporal dynamics\n",
        "3. **Stability**: Well-understood dynamics with spectral radius control\n",
        "4. **Interpretability**: Easier to analyze than deep networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Environment Setup\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from typing import List, Dict, Any, Tuple, Optional\n",
        "from dataclasses import dataclass, field\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Load environment\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "GATEWAY_URL = os.getenv('REGIMA_GATEWAY_URL', 'http://localhost:3000')\n",
        "API_KEY = os.getenv('REGIMA_API_KEY', 'demo-key')\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Data Structures\n",
        "\n",
        "Define the data structures for progression modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@dataclass\n",
        "class ProgressionDataPoint:\n",
        "    \"\"\"A single observation in the progression timeline\"\"\"\n",
        "    timestamp: datetime\n",
        "    severity: float  # 0.0 (clear) to 1.0 (severe)\n",
        "    treatment_active: bool = False\n",
        "    treatment_type: Optional[str] = None\n",
        "    environmental_factors: Dict[str, float] = field(default_factory=dict)\n",
        "    \n",
        "    def to_vector(self) -> np.ndarray:\n",
        "        \"\"\"Convert to feature vector for ESN input\"\"\"\n",
        "        # Day of year (normalized) - captures seasonality\n",
        "        day_of_year = self.timestamp.timetuple().tm_yday / 365.0\n",
        "        \n",
        "        # Day of week (normalized) - captures weekly patterns\n",
        "        day_of_week = self.timestamp.weekday() / 6.0\n",
        "        \n",
        "        # Environmental factors\n",
        "        humidity = self.environmental_factors.get('humidity', 0.5)\n",
        "        temperature = self.environmental_factors.get('temperature', 0.5)\n",
        "        stress_level = self.environmental_factors.get('stress', 0.3)\n",
        "        \n",
        "        return np.array([\n",
        "            self.severity,\n",
        "            float(self.treatment_active),\n",
        "            day_of_year,\n",
        "            day_of_week,\n",
        "            humidity,\n",
        "            temperature,\n",
        "            stress_level\n",
        "        ])\n",
        "\n",
        "@dataclass\n",
        "class ProgressionPrediction:\n",
        "    \"\"\"A prediction for future progression\"\"\"\n",
        "    timestamp: datetime\n",
        "    predicted_severity: float\n",
        "    confidence: float\n",
        "    lower_bound: float\n",
        "    upper_bound: float\n",
        "    \n",
        "    def to_dict(self) -> Dict:\n",
        "        return {\n",
        "            \"date\": self.timestamp.isoformat(),\n",
        "            \"predicted_severity\": round(self.predicted_severity, 4),\n",
        "            \"confidence\": round(self.confidence, 4),\n",
        "            \"confidence_interval\": {\n",
        "                \"lower\": round(self.lower_bound, 4),\n",
        "                \"upper\": round(self.upper_bound, 4)\n",
        "            }\n",
        "        }\n",
        "\n",
        "@dataclass\n",
        "class PatientProgression:\n",
        "    \"\"\"Complete progression history for a patient\"\"\"\n",
        "    patient_id: str\n",
        "    condition: str\n",
        "    data_points: List[ProgressionDataPoint]\n",
        "    \n",
        "    def to_matrix(self) -> np.ndarray:\n",
        "        \"\"\"Convert to input matrix for ESN\"\"\"\n",
        "        return np.array([dp.to_vector() for dp in self.data_points])\n",
        "    \n",
        "    def get_severities(self) -> np.ndarray:\n",
        "        \"\"\"Get severity values as target array\"\"\"\n",
        "        return np.array([dp.severity for dp in self.data_points])\n",
        "\n",
        "print(\"Data structures loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Echo State Network Implementation\n",
        "\n",
        "Core ESN implementation for temporal progression modeling."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class EchoStateNetwork:\n",
        "    \"\"\"Echo State Network for skin condition progression prediction\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        input_size: int = 7,\n",
        "        reservoir_size: int = 500,\n",
        "        output_size: int = 1,\n",
        "        spectral_radius: float = 0.95,\n",
        "        input_scaling: float = 0.5,\n",
        "        leaking_rate: float = 0.3,\n",
        "        regularization: float = 1e-6,\n",
        "        sparsity: float = 0.1\n",
        "    ):\n",
        "        self.input_size = input_size\n",
        "        self.reservoir_size = reservoir_size\n",
        "        self.output_size = output_size\n",
        "        self.spectral_radius = spectral_radius\n",
        "        self.input_scaling = input_scaling\n",
        "        self.leaking_rate = leaking_rate\n",
        "        self.regularization = regularization\n",
        "        self.sparsity = sparsity\n",
        "        \n",
        "        # Initialize reservoir\n",
        "        self._initialize_weights()\n",
        "        \n",
        "        # Output weights (to be trained)\n",
        "        self.W_out = None\n",
        "        \n",
        "        # Training state\n",
        "        self.is_trained = False\n",
        "        self.training_error = None\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        \"\"\"Initialize reservoir and input weights\"\"\"\n",
        "        # Sparse reservoir weight matrix\n",
        "        W_reservoir = np.random.randn(self.reservoir_size, self.reservoir_size)\n",
        "        mask = np.random.rand(self.reservoir_size, self.reservoir_size) < self.sparsity\n",
        "        W_reservoir *= mask\n",
        "        \n",
        "        # Scale to desired spectral radius\n",
        "        eigenvalues = np.linalg.eigvals(W_reservoir)\n",
        "        current_spectral_radius = np.max(np.abs(eigenvalues))\n",
        "        if current_spectral_radius > 0:\n",
        "            W_reservoir *= self.spectral_radius / current_spectral_radius\n",
        "        \n",
        "        self.W_reservoir = W_reservoir\n",
        "        \n",
        "        # Input weight matrix\n",
        "        self.W_in = np.random.randn(self.reservoir_size, self.input_size) * self.input_scaling\n",
        "        \n",
        "        # Bias\n",
        "        self.bias = np.random.randn(self.reservoir_size) * 0.1\n",
        "    \n",
        "    def _update_reservoir(self, state: np.ndarray, input_vector: np.ndarray) -> np.ndarray:\n",
        "        \"\"\"Update reservoir state with leaky integration\"\"\"\n",
        "        pre_activation = (\n",
        "            np.dot(self.W_reservoir, state) +\n",
        "            np.dot(self.W_in, input_vector) +\n",
        "            self.bias\n",
        "        )\n",
        "        new_state = np.tanh(pre_activation)\n",
        "        \n",
        "        # Leaky integration\n",
        "        return (1 - self.leaking_rate) * state + self.leaking_rate * new_state\n",
        "    \n",
        "    def _collect_states(self, inputs: np.ndarray, washout: int = 50) -> np.ndarray:\n",
        "        \"\"\"Collect reservoir states for all inputs\"\"\"\n",
        "        T = inputs.shape[0]\n",
        "        states = np.zeros((T, self.reservoir_size))\n",
        "        state = np.zeros(self.reservoir_size)\n",
        "        \n",
        "        for t in range(T):\n",
        "            state = self._update_reservoir(state, inputs[t])\n",
        "            states[t] = state\n",
        "        \n",
        "        # Return states after washout period\n",
        "        return states[washout:]\n",
        "    \n",
        "    def fit(self, inputs: np.ndarray, targets: np.ndarray, washout: int = 50):\n",
        "        \"\"\"Train the ESN on time series data\"\"\"\n",
        "        # Collect reservoir states\n",
        "        states = self._collect_states(inputs, washout)\n",
        "        targets_trimmed = targets[washout:]\n",
        "        \n",
        "        # Add bias to states\n",
        "        extended_states = np.hstack([states, np.ones((states.shape[0], 1))])\n",
        "        \n",
        "        # Ridge regression for output weights\n",
        "        reg_matrix = self.regularization * np.eye(extended_states.shape[1])\n",
        "        self.W_out = np.linalg.solve(\n",
        "            extended_states.T @ extended_states + reg_matrix,\n",
        "            extended_states.T @ targets_trimmed\n",
        "        )\n",
        "        \n",
        "        # Calculate training error\n",
        "        predictions = extended_states @ self.W_out\n",
        "        self.training_error = np.mean((predictions - targets_trimmed) ** 2)\n",
        "        self.is_trained = True\n",
        "        \n",
        "        return self\n",
        "    \n",
        "    def predict(\n",
        "        self,\n",
        "        initial_inputs: np.ndarray,\n",
        "        horizon: int,\n",
        "        return_confidence: bool = True\n",
        "    ) -> Tuple[np.ndarray, Optional[np.ndarray]]:\n",
        "        \"\"\"Predict future progression\"\"\"\n",
        "        if not self.is_trained:\n",
        "            raise ValueError(\"ESN must be trained before prediction\")\n",
        "        \n",
        "        # Warm up reservoir with initial inputs\n",
        "        state = np.zeros(self.reservoir_size)\n",
        "        for t in range(len(initial_inputs)):\n",
        "            state = self._update_reservoir(state, initial_inputs[t])\n",
        "        \n",
        "        # Generate predictions\n",
        "        predictions = []\n",
        "        last_input = initial_inputs[-1].copy()\n",
        "        \n",
        "        for _ in range(horizon):\n",
        "            state = self._update_reservoir(state, last_input)\n",
        "            extended_state = np.append(state, 1)  # Add bias\n",
        "            pred = extended_state @ self.W_out\n",
        "            pred = np.clip(pred, 0, 1)  # Severity bounded [0, 1]\n",
        "            predictions.append(pred)\n",
        "            \n",
        "            # Update input with prediction for next step\n",
        "            last_input[0] = pred  # Severity is first feature\n",
        "        \n",
        "        predictions = np.array(predictions)\n",
        "        \n",
        "        if return_confidence:\n",
        "            # Estimate confidence based on prediction horizon\n",
        "            confidence = self._estimate_confidence(horizon)\n",
        "            return predictions, confidence\n",
        "        \n",
        "        return predictions, None\n",
        "    \n",
        "    def _estimate_confidence(self, horizon: int) -> np.ndarray:\n",
        "        \"\"\"Estimate prediction confidence that decays with horizon\"\"\"\n",
        "        base_confidence = 0.95 - np.sqrt(self.training_error) * 0.5\n",
        "        decay_rate = 0.02  # 2% confidence decay per step\n",
        "        \n",
        "        confidence = np.array([\n",
        "            max(0.3, base_confidence * np.exp(-decay_rate * t))\n",
        "            for t in range(horizon)\n",
        "        ])\n",
        "        \n",
        "        return confidence\n",
        "\n",
        "print(\"ESN implementation loaded\")\n",
        "print(f\"Reservoir size: 500, Spectral radius: 0.95\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Progression Predictor\n",
        "\n",
        "High-level interface for dermatological progression prediction."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class ProgressionPredictor:\n",
        "    \"\"\"Dermatological progression predictor using ESN\"\"\"\n",
        "    \n",
        "    def __init__(self, esn_config: Dict = None):\n",
        "        config = esn_config or {}\n",
        "        self.esn = EchoStateNetwork(\n",
        "            reservoir_size=config.get('reservoir_size', 500),\n",
        "            spectral_radius=config.get('spectral_radius', 0.95),\n",
        "            input_scaling=config.get('input_scaling', 0.5),\n",
        "            leaking_rate=config.get('leaking_rate', 0.3),\n",
        "            regularization=config.get('regularization', 1e-6)\n",
        "        )\n",
        "        self.condition_baselines = self._load_condition_baselines()\n",
        "    \n",
        "    def _load_condition_baselines(self) -> Dict:\n",
        "        \"\"\"Load baseline progression patterns for conditions\"\"\"\n",
        "        return {\n",
        "            'acne_vulgaris': {\n",
        "                'typical_duration_weeks': 12,\n",
        "                'natural_improvement_rate': 0.05,\n",
        "                'treatment_improvement_rate': 0.15,\n",
        "                'flare_probability': 0.2,\n",
        "                'seasonal_factors': {'summer': 0.1, 'winter': -0.05}\n",
        "            },\n",
        "            'psoriasis': {\n",
        "                'typical_duration_weeks': 24,\n",
        "                'natural_improvement_rate': 0.02,\n",
        "                'treatment_improvement_rate': 0.10,\n",
        "                'flare_probability': 0.3,\n",
        "                'seasonal_factors': {'winter': 0.15, 'summer': -0.10}\n",
        "            },\n",
        "            'eczema': {\n",
        "                'typical_duration_weeks': 8,\n",
        "                'natural_improvement_rate': 0.03,\n",
        "                'treatment_improvement_rate': 0.12,\n",
        "                'flare_probability': 0.25,\n",
        "                'seasonal_factors': {'winter': 0.20, 'summer': -0.05}\n",
        "            },\n",
        "            'rosacea': {\n",
        "                'typical_duration_weeks': 16,\n",
        "                'natural_improvement_rate': 0.01,\n",
        "                'treatment_improvement_rate': 0.08,\n",
        "                'flare_probability': 0.35,\n",
        "                'seasonal_factors': {'summer': 0.15, 'winter': 0.05}\n",
        "            }\n",
        "        }\n",
        "    \n",
        "    def train(self, progression: PatientProgression, washout: int = 10):\n",
        "        \"\"\"Train ESN on patient progression data\"\"\"\n",
        "        inputs = progression.to_matrix()\n",
        "        targets = progression.get_severities().reshape(-1, 1)\n",
        "        \n",
        "        # Adjust washout based on data length\n",
        "        washout = min(washout, len(inputs) // 3)\n",
        "        \n",
        "        self.esn.fit(inputs, targets, washout=washout)\n",
        "        print(f\"Training complete. MSE: {self.esn.training_error:.6f}\")\n",
        "    \n",
        "    def predict_progression(\n",
        "        self,\n",
        "        progression: PatientProgression,\n",
        "        horizon_days: int = 30,\n",
        "        treatment_plan: Dict = None\n",
        "    ) -> List[ProgressionPrediction]:\n",
        "        \"\"\"Predict future progression\"\"\"\n",
        "        inputs = progression.to_matrix()\n",
        "        \n",
        "        # Predict\n",
        "        predictions, confidence = self.esn.predict(inputs, horizon_days)\n",
        "        \n",
        "        # Apply condition-specific adjustments\n",
        "        baseline = self.condition_baselines.get(progression.condition, {})\n",
        "        \n",
        "        # Create prediction objects\n",
        "        results = []\n",
        "        last_date = progression.data_points[-1].timestamp\n",
        "        \n",
        "        for day in range(horizon_days):\n",
        "            pred_date = last_date + timedelta(days=day + 1)\n",
        "            pred_value = float(predictions[day])\n",
        "            conf = float(confidence[day])\n",
        "            \n",
        "            # Apply treatment effect if specified\n",
        "            if treatment_plan and treatment_plan.get('active'):\n",
        "                improvement_rate = baseline.get('treatment_improvement_rate', 0.1)\n",
        "                pred_value = max(0, pred_value - improvement_rate * (day / 30))\n",
        "            \n",
        "            # Calculate confidence interval\n",
        "            interval_width = (1 - conf) * 0.5\n",
        "            lower = max(0, pred_value - interval_width)\n",
        "            upper = min(1, pred_value + interval_width)\n",
        "            \n",
        "            results.append(ProgressionPrediction(\n",
        "                timestamp=pred_date,\n",
        "                predicted_severity=pred_value,\n",
        "                confidence=conf,\n",
        "                lower_bound=lower,\n",
        "                upper_bound=upper\n",
        "            ))\n",
        "        \n",
        "        return results\n",
        "    \n",
        "    def estimate_healing_time(\n",
        "        self,\n",
        "        progression: PatientProgression,\n",
        "        target_severity: float = 0.1,\n",
        "        max_days: int = 180\n",
        "    ) -> Dict:\n",
        "        \"\"\"Estimate time to reach target severity\"\"\"\n",
        "        predictions = self.predict_progression(progression, horizon_days=max_days)\n",
        "        \n",
        "        healing_day = None\n",
        "        for i, pred in enumerate(predictions):\n",
        "            if pred.predicted_severity <= target_severity:\n",
        "                healing_day = i + 1\n",
        "                break\n",
        "        \n",
        "        if healing_day:\n",
        "            return {\n",
        "                'estimated_days': healing_day,\n",
        "                'target_severity': target_severity,\n",
        "                'confidence': predictions[healing_day - 1].confidence,\n",
        "                'target_date': predictions[healing_day - 1].timestamp.isoformat(),\n",
        "                'status': 'healing_expected'\n",
        "            }\n",
        "        else:\n",
        "            return {\n",
        "                'estimated_days': None,\n",
        "                'target_severity': target_severity,\n",
        "                'status': 'healing_not_predicted_in_window',\n",
        "                'final_predicted_severity': predictions[-1].predicted_severity,\n",
        "                'recommendation': 'Consider treatment adjustment'\n",
        "            }\n",
        "    \n",
        "    def analyze_patterns(\n",
        "        self,\n",
        "        progression: PatientProgression\n",
        "    ) -> Dict:\n",
        "        \"\"\"Analyze temporal patterns in progression\"\"\"\n",
        "        severities = progression.get_severities()\n",
        "        \n",
        "        # Basic statistics\n",
        "        stats = {\n",
        "            'mean_severity': float(np.mean(severities)),\n",
        "            'std_severity': float(np.std(severities)),\n",
        "            'max_severity': float(np.max(severities)),\n",
        "            'min_severity': float(np.min(severities)),\n",
        "            'trend': self._calculate_trend(severities)\n",
        "        }\n",
        "        \n",
        "        # Detect flares\n",
        "        flares = self._detect_flares(severities)\n",
        "        \n",
        "        # Detect periodicity\n",
        "        periodicity = self._detect_periodicity(severities)\n",
        "        \n",
        "        return {\n",
        "            'statistics': stats,\n",
        "            'flares': flares,\n",
        "            'periodicity': periodicity,\n",
        "            'data_points_analyzed': len(severities)\n",
        "        }\n",
        "    \n",
        "    def _calculate_trend(self, severities: np.ndarray) -> str:\n",
        "        \"\"\"Calculate overall trend\"\"\"\n",
        "        if len(severities) < 3:\n",
        "            return 'insufficient_data'\n",
        "        \n",
        "        # Simple linear regression slope\n",
        "        x = np.arange(len(severities))\n",
        "        slope = np.polyfit(x, severities, 1)[0]\n",
        "        \n",
        "        if slope < -0.01:\n",
        "            return 'improving'\n",
        "        elif slope > 0.01:\n",
        "            return 'worsening'\n",
        "        else:\n",
        "            return 'stable'\n",
        "    \n",
        "    def _detect_flares(self, severities: np.ndarray) -> Dict:\n",
        "        \"\"\"Detect flare events in the progression\"\"\"\n",
        "        if len(severities) < 5:\n",
        "            return {'count': 0, 'events': []}\n",
        "        \n",
        "        mean = np.mean(severities)\n",
        "        std = np.std(severities)\n",
        "        threshold = mean + 1.5 * std\n",
        "        \n",
        "        flares = []\n",
        "        in_flare = False\n",
        "        flare_start = 0\n",
        "        \n",
        "        for i, sev in enumerate(severities):\n",
        "            if sev > threshold and not in_flare:\n",
        "                in_flare = True\n",
        "                flare_start = i\n",
        "            elif sev <= threshold and in_flare:\n",
        "                in_flare = False\n",
        "                flares.append({\n",
        "                    'start_index': flare_start,\n",
        "                    'end_index': i - 1,\n",
        "                    'duration': i - flare_start,\n",
        "                    'peak_severity': float(np.max(severities[flare_start:i]))\n",
        "                })\n",
        "        \n",
        "        return {\n",
        "            'count': len(flares),\n",
        "            'threshold': float(threshold),\n",
        "            'events': flares\n",
        "        }\n",
        "    \n",
        "    def _detect_periodicity(self, severities: np.ndarray) -> Dict:\n",
        "        \"\"\"Detect periodic patterns using autocorrelation\"\"\"\n",
        "        if len(severities) < 14:\n",
        "            return {'detected': False, 'reason': 'insufficient_data'}\n",
        "        \n",
        "        # Calculate autocorrelation\n",
        "        n = len(severities)\n",
        "        mean = np.mean(severities)\n",
        "        var = np.var(severities)\n",
        "        \n",
        "        if var == 0:\n",
        "            return {'detected': False, 'reason': 'no_variance'}\n",
        "        \n",
        "        autocorr = []\n",
        "        for lag in range(1, min(n // 2, 60)):\n",
        "            corr = np.mean((severities[:-lag] - mean) * (severities[lag:] - mean)) / var\n",
        "            autocorr.append((lag, corr))\n",
        "        \n",
        "        # Find peaks in autocorrelation\n",
        "        peaks = [(lag, corr) for lag, corr in autocorr if corr > 0.3]\n",
        "        \n",
        "        if peaks:\n",
        "            best_period = peaks[0][0]\n",
        "            return {\n",
        "                'detected': True,\n",
        "                'period_days': best_period,\n",
        "                'correlation_strength': float(peaks[0][1]),\n",
        "                'pattern_type': self._classify_period(best_period)\n",
        "            }\n",
        "        \n",
        "        return {'detected': False, 'reason': 'no_significant_periodicity'}\n",
        "    \n",
        "    def _classify_period(self, period: int) -> str:\n",
        "        \"\"\"Classify the type of periodic pattern\"\"\"\n",
        "        if period <= 7:\n",
        "            return 'weekly'\n",
        "        elif period <= 14:\n",
        "            return 'biweekly'\n",
        "        elif period <= 35:\n",
        "            return 'monthly'\n",
        "        else:\n",
        "            return 'seasonal'\n",
        "\n",
        "print(\"ProgressionPredictor loaded successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate Synthetic Data and Demo\n",
        "\n",
        "Demonstrate the ESN progression predictor with synthetic patient data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_progression(\n",
        "    condition: str,\n",
        "    days: int = 90,\n",
        "    initial_severity: float = 0.7,\n",
        "    treatment_start_day: int = 14,\n",
        "    add_noise: bool = True\n",
        ") -> PatientProgression:\n",
        "    \"\"\"Generate synthetic progression data for testing\"\"\"\n",
        "    data_points = []\n",
        "    base_date = datetime(2024, 1, 1)\n",
        "    \n",
        "    severity = initial_severity\n",
        "    \n",
        "    for day in range(days):\n",
        "        current_date = base_date + timedelta(days=day)\n",
        "        treatment_active = day >= treatment_start_day\n",
        "        \n",
        "        # Simulate progression\n",
        "        if treatment_active:\n",
        "            # Treatment effect\n",
        "            severity *= 0.98  # 2% improvement per day\n",
        "        else:\n",
        "            # Natural fluctuation\n",
        "            severity += np.random.normal(0, 0.02)\n",
        "        \n",
        "        # Add periodic flare (every ~28 days)\n",
        "        if day % 28 < 3 and np.random.random() < 0.5:\n",
        "            severity += 0.15\n",
        "        \n",
        "        # Add random noise\n",
        "        if add_noise:\n",
        "            severity += np.random.normal(0, 0.03)\n",
        "        \n",
        "        # Clamp severity\n",
        "        severity = np.clip(severity, 0.05, 0.95)\n",
        "        \n",
        "        # Environmental factors\n",
        "        month = current_date.month\n",
        "        humidity = 0.5 + 0.2 * np.sin(2 * np.pi * month / 12)\n",
        "        temperature = 0.5 + 0.3 * np.sin(2 * np.pi * (month - 3) / 12)\n",
        "        \n",
        "        data_points.append(ProgressionDataPoint(\n",
        "            timestamp=current_date,\n",
        "            severity=float(severity),\n",
        "            treatment_active=treatment_active,\n",
        "            treatment_type='topical_retinoid' if treatment_active else None,\n",
        "            environmental_factors={\n",
        "                'humidity': humidity,\n",
        "                'temperature': temperature,\n",
        "                'stress': np.random.uniform(0.2, 0.5)\n",
        "            }\n",
        "        ))\n",
        "    \n",
        "    return PatientProgression(\n",
        "        patient_id='synthetic-patient-001',\n",
        "        condition=condition,\n",
        "        data_points=data_points\n",
        "    )\n",
        "\n",
        "# Generate synthetic data\n",
        "progression = generate_synthetic_progression(\n",
        "    condition='acne_vulgaris',\n",
        "    days=60,\n",
        "    initial_severity=0.75\n",
        ")\n",
        "\n",
        "print(f\"Generated {len(progression.data_points)} data points\")\n",
        "print(f\"Condition: {progression.condition}\")\n",
        "print(f\"Date range: {progression.data_points[0].timestamp.date()} to {progression.data_points[-1].timestamp.date()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train the predictor\n",
        "predictor = ProgressionPredictor({\n",
        "    'reservoir_size': 300,\n",
        "    'spectral_radius': 0.9,\n",
        "    'leaking_rate': 0.3\n",
        "})\n",
        "\n",
        "predictor.train(progression)\n",
        "\n",
        "# Predict future progression\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PREDICTING NEXT 30 DAYS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "predictions = predictor.predict_progression(\n",
        "    progression,\n",
        "    horizon_days=30,\n",
        "    treatment_plan={'active': True}\n",
        ")\n",
        "\n",
        "print(\"\\nPredictions (every 5 days):\")\n",
        "for i in range(0, 30, 5):\n",
        "    pred = predictions[i]\n",
        "    print(f\"  Day {i+1}: Severity={pred.predicted_severity:.3f} \"\n",
        "          f\"(Confidence: {pred.confidence:.2f}, CI: [{pred.lower_bound:.3f}, {pred.upper_bound:.3f}])\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analyze patterns\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"PATTERN ANALYSIS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "patterns = predictor.analyze_patterns(progression)\n",
        "\n",
        "print(f\"\\nStatistics:\")\n",
        "print(f\"  Mean severity: {patterns['statistics']['mean_severity']:.3f}\")\n",
        "print(f\"  Std deviation: {patterns['statistics']['std_severity']:.3f}\")\n",
        "print(f\"  Trend: {patterns['statistics']['trend']}\")\n",
        "\n",
        "print(f\"\\nFlare Detection:\")\n",
        "print(f\"  Flares detected: {patterns['flares']['count']}\")\n",
        "\n",
        "print(f\"\\nPeriodicity:\")\n",
        "if patterns['periodicity']['detected']:\n",
        "    print(f\"  Period: {patterns['periodicity']['period_days']} days\")\n",
        "    print(f\"  Pattern type: {patterns['periodicity']['pattern_type']}\")\n",
        "else:\n",
        "    print(f\"  No significant periodicity detected\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Estimate healing time\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"HEALING TIME ESTIMATION\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "healing_estimate = predictor.estimate_healing_time(\n",
        "    progression,\n",
        "    target_severity=0.2,\n",
        "    max_days=90\n",
        ")\n",
        "\n",
        "print(f\"\\nTarget severity: {healing_estimate['target_severity']}\")\n",
        "if healing_estimate['estimated_days']:\n",
        "    print(f\"Estimated days to target: {healing_estimate['estimated_days']}\")\n",
        "    print(f\"Target date: {healing_estimate['target_date']}\")\n",
        "    print(f\"Confidence: {healing_estimate['confidence']:.2f}\")\n",
        "else:\n",
        "    print(f\"Status: {healing_estimate['status']}\")\n",
        "    print(f\"Final predicted severity: {healing_estimate.get('final_predicted_severity', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "def plot_progression_with_predictions(\n",
        "    progression: PatientProgression,\n",
        "    predictions: List[ProgressionPrediction]\n",
        "):\n",
        "    \"\"\"Plot historical progression with future predictions\"\"\"\n",
        "    fig, ax = plt.subplots(figsize=(12, 6))\n",
        "    \n",
        "    # Historical data\n",
        "    hist_dates = [dp.timestamp for dp in progression.data_points]\n",
        "    hist_severities = [dp.severity for dp in progression.data_points]\n",
        "    ax.plot(hist_dates, hist_severities, 'b-', linewidth=2, label='Historical', marker='o', markersize=3)\n",
        "    \n",
        "    # Treatment start indicator\n",
        "    for i, dp in enumerate(progression.data_points):\n",
        "        if dp.treatment_active and (i == 0 or not progression.data_points[i-1].treatment_active):\n",
        "            ax.axvline(x=dp.timestamp, color='green', linestyle='--', alpha=0.7, label='Treatment Start')\n",
        "            break\n",
        "    \n",
        "    # Predictions\n",
        "    pred_dates = [p.timestamp for p in predictions]\n",
        "    pred_severities = [p.predicted_severity for p in predictions]\n",
        "    pred_lower = [p.lower_bound for p in predictions]\n",
        "    pred_upper = [p.upper_bound for p in predictions]\n",
        "    \n",
        "    ax.plot(pred_dates, pred_severities, 'r-', linewidth=2, label='Predicted', marker='s', markersize=3)\n",
        "    ax.fill_between(pred_dates, pred_lower, pred_upper, color='red', alpha=0.2, label='95% CI')\n",
        "    \n",
        "    # Formatting\n",
        "    ax.set_xlabel('Date', fontsize=12)\n",
        "    ax.set_ylabel('Severity (0-1)', fontsize=12)\n",
        "    ax.set_title(f'Skin Condition Progression: {progression.condition.replace(\"_\", \" \").title()}', fontsize=14)\n",
        "    ax.legend(loc='upper right')\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.set_ylim(0, 1)\n",
        "    \n",
        "    ax.xaxis.set_major_formatter(mdates.DateFormatter('%b %d'))\n",
        "    ax.xaxis.set_major_locator(mdates.WeekdayLocator(interval=2))\n",
        "    plt.xticks(rotation=45)\n",
        "    \n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Plot the progression\n",
        "plot_progression_with_predictions(progression, predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Gateway Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "\n",
        "class ESNGatewayClient:\n",
        "    \"\"\"Client for ESN progression prediction through RegimAI Gateway\"\"\"\n",
        "    \n",
        "    def __init__(self, gateway_url: str, api_key: str):\n",
        "        self.gateway_url = gateway_url.rstrip('/')\n",
        "        self.api_key = api_key\n",
        "        self.headers = {\n",
        "            \"X-API-Key\": api_key,\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "    \n",
        "    def predict_progression(\n",
        "        self,\n",
        "        condition: str,\n",
        "        patient_id: str,\n",
        "        historical_data: List[Dict],\n",
        "        prediction_horizon_days: int = 30\n",
        "    ) -> Dict:\n",
        "        \"\"\"Request progression prediction from gateway\"\"\"\n",
        "        payload = {\n",
        "            \"condition\": condition,\n",
        "            \"patient_id\": patient_id,\n",
        "            \"historical_data\": historical_data,\n",
        "            \"prediction_horizon_days\": prediction_horizon_days,\n",
        "            \"include_confidence_intervals\": True\n",
        "        }\n",
        "        \n",
        "        response = requests.post(\n",
        "            f\"{self.gateway_url}/cognitive/esn/predict\",\n",
        "            headers=self.headers,\n",
        "            json=payload\n",
        "        )\n",
        "        \n",
        "        return response.json()\n",
        "    \n",
        "    def analyze_patterns(\n",
        "        self,\n",
        "        condition: str,\n",
        "        patient_id: str,\n",
        "        historical_data: List[Dict]\n",
        "    ) -> Dict:\n",
        "        \"\"\"Request pattern analysis from gateway\"\"\"\n",
        "        payload = {\n",
        "            \"condition\": condition,\n",
        "            \"patient_id\": patient_id,\n",
        "            \"historical_data\": historical_data\n",
        "        }\n",
        "        \n",
        "        response = requests.post(\n",
        "            f\"{self.gateway_url}/cognitive/esn/patterns/analyze\",\n",
        "            headers=self.headers,\n",
        "            json=payload\n",
        "        )\n",
        "        \n",
        "        return response.json()\n",
        "    \n",
        "    def estimate_healing_time(\n",
        "        self,\n",
        "        condition: str,\n",
        "        patient_id: str,\n",
        "        historical_data: List[Dict],\n",
        "        target_severity: float = 0.1\n",
        "    ) -> Dict:\n",
        "        \"\"\"Request healing time estimation from gateway\"\"\"\n",
        "        payload = {\n",
        "            \"condition\": condition,\n",
        "            \"patient_id\": patient_id,\n",
        "            \"historical_data\": historical_data,\n",
        "            \"target_severity\": target_severity\n",
        "        }\n",
        "        \n",
        "        response = requests.post(\n",
        "            f\"{self.gateway_url}/cognitive/esn/healing/estimate\",\n",
        "            headers=self.headers,\n",
        "            json=payload\n",
        "        )\n",
        "        \n",
        "        return response.json()\n",
        "\n",
        "print(\"ESN Gateway Client ready\")\n",
        "print(f\"Gateway URL: {GATEWAY_URL}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "This lab demonstrates:\n",
        "\n",
        "1. **Echo State Networks**: Reservoir computing for time series prediction\n",
        "2. **Progression Modeling**: Predicting skin condition severity over time\n",
        "3. **Pattern Analysis**: Detecting flares, trends, and periodicity\n",
        "4. **Healing Estimation**: Predicting time to recovery\n",
        "5. **Gateway Integration**: API access through RegimAI Gateway\n",
        "\n",
        "### Integration with SkinTwin Architecture\n",
        "\n",
        "- **AtomSpace**: Store progression patterns as temporal relationships\n",
        "- **PLN**: Reason about treatment efficacy from progression data\n",
        "- **MOSES**: Optimize treatments based on predicted responses\n",
        "- **ECAN**: Prioritize attention on high-risk progression patterns"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
